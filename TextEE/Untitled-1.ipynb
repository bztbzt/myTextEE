{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from argparse import Namespace\n",
    "from models import *\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertConfig, RobertaConfig, XLMRobertaConfig, BertModel, RobertaModel, XLMRobertaModel,RobertaTokenizer\n",
    "from collections import namedtuple\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"EAE\";\n",
    "dataset = \"phee\";\n",
    "split = 1;\n",
    "model_type = \"TagPrime\";\n",
    "pretrained_model_name = \"roberta-base\";\n",
    "pretrained_model_alias = {\n",
    "    \"roberta-base\": \"roberta-base\", \n",
    "};\n",
    "\n",
    "config_dict = {\n",
    "                #// general config\n",
    "                \"task\": task, \n",
    "                \"dataset\": dataset,\n",
    "                \"model_type\": model_type, \n",
    "                \"gpu_device\": 0, \n",
    "                \"seed\": 0, \n",
    "                \"cache_dir\": \"./cache\", \n",
    "                \"train_file\": \"../data/processed_data/%s/split%s/train.json\" % (dataset, split),\n",
    "                \"dev_file\": \"../data/processed_data/%s/split%s/dev.json\" % (dataset, split),\n",
    "                \"test_file\": \"../data/processed_data/%s/split%s/test.json\" % (dataset, split),\n",
    "                \n",
    "                #// model config\n",
    "                \"pretrained_model_name\": pretrained_model_name,\n",
    "                \"base_model_dropout\": 0.2,\n",
    "                \"use_crf\": True,\n",
    "                \"use_trigger_feature\": True,\n",
    "                \"use_type_feature\": True, \n",
    "                \"type_feature_num\": 100, \n",
    "                \"linear_hidden_num\": 150,\n",
    "                \"linear_dropout\": 0.2,\n",
    "                \"linear_bias\": True, \n",
    "                \"linear_activation\": \"relu\",\n",
    "                \"multi_piece_strategy\": \"average\", \n",
    "                \"priming_type\": \"condition\", \n",
    "                \"max_length\": 200, \n",
    "                \n",
    "                #// train config\n",
    "                \"max_epoch\": 90,\n",
    "                \"warmup_epoch\": 5,\n",
    "                \"accumulate_step\": 1,\n",
    "                \"train_batch_size\": 6,\n",
    "                \"eval_batch_size\": 12,\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"base_model_learning_rate\": 1e-05,\n",
    "                \"weight_decay\": 0.001,\n",
    "                \"base_model_weight_decay\": 1e-05,\n",
    "                \"grad_clipping\": 5.0,\n",
    "            }\n",
    "\n",
    "config = Namespace(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trainer\n",
    "VALID_TASKS = [\"E2E\", \"ED\", \"EAE\", \"EARL\"]\n",
    "\n",
    "TRAINER_MAP = {\n",
    "\n",
    "    (\"CRFTagging\", \"ED\"): CRFTaggingEDTrainer, \n",
    "    (\"CRFTagging\", \"EAE\"): CRFTaggingEAETrainer,\n",
    "    (\"TagPrime\", \"ED\"): TagPrimeEDTrainer, \n",
    "    (\"TagPrime\", \"EAE\"): TagPrimeEAETrainer\n",
    "}\n",
    "trainer_class = TRAINER_MAP[(config.model_type, config.task)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2987 EAE instances (2 trigger types and 16 role types) from ../data/processed_data/phee/split1/train.json\n",
      "combine cnt :16\n",
      "Loaded 1005 EAE instances (2 trigger types and 16 role types) from ../data/processed_data/phee/split1/dev.json\n",
      "combine cnt :6\n",
      "Loaded 1003 EAE instances (2 trigger types and 16 role types) from ../data/processed_data/phee/split1/test.json\n",
      "combine cnt :2\n",
      "There are 2 trigger types and 16 role types in total\n"
     ]
    }
   ],
   "source": [
    "def load_EAE_data(file, add_extra_info_fn, config):\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as fp:\n",
    "        lines = fp.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "    \n",
    "    instances = []\n",
    "    cnt = 0\n",
    "    for dt in data:\n",
    "        \n",
    "        entities = dt['entity_mentions']\n",
    "\n",
    "        event_mentions = dt['event_mentions']\n",
    "        event_mentions.sort(key=lambda x: x['trigger']['start'])\n",
    "        entity_map = {entity['id']: entity for entity in entities}\n",
    "        ins = {}\n",
    "        for i, event_mention in enumerate(event_mentions):\n",
    "            # trigger = (start index, end index, event type, text span)\n",
    "            trigger = (event_mention['trigger']['start'], \n",
    "                       event_mention['trigger']['end'], \n",
    "                       event_mention['event_type'], \n",
    "                       event_mention['trigger']['text'])\n",
    "            arguments = []\n",
    "            for arg in event_mention['arguments']:\n",
    "                mapped_entity = entity_map[arg['entity_id']]\n",
    "                \n",
    "                # argument = (start index, end index, role type, text span)\n",
    "                argument = (mapped_entity['start'], mapped_entity['end'], arg['role'], arg['text'])\n",
    "                arguments.append(argument)\n",
    "\n",
    "            arguments.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "            ### if trigger and event type same , combine the arguments !!!\n",
    "            if trigger not in ins.keys():\n",
    "                ins[trigger] = arguments\n",
    "            else:\n",
    "                for item in arguments:\n",
    "                    ins[trigger].append(item)\n",
    "                cnt+=1\n",
    "\n",
    "        for i in range(len(ins.keys())):\n",
    "            instance = {\"doc_id\": dt[\"doc_id\"], \n",
    "                        \"wnd_id\": dt[\"wnd_id\"], \n",
    "                        \"tokens\": dt[\"tokens\"], \n",
    "                        \"text\": dt[\"text\"], \n",
    "                        \"trigger\": list(ins.keys())[i], \n",
    "                        \"arguments\": ins[list(ins.keys())[i]], \n",
    "                    }\n",
    "            instances.append(instance)\n",
    "            \n",
    "    trigger_type_set = set()\n",
    "    for instance in instances:\n",
    "        trigger_type_set.add(instance['trigger'][2])\n",
    "\n",
    "    role_type_set = set()\n",
    "    for instance in instances:\n",
    "        for argument in instance[\"arguments\"]:\n",
    "            role_type_set.add(argument[2])\n",
    "                \n",
    "    type_set = {\"trigger\": trigger_type_set, \"role\": role_type_set}\n",
    "    \n",
    "    # approach-specific preprocessing\n",
    "    new_instances = add_extra_info_fn(instances, data, config)\n",
    "    assert len(new_instances) == len(instances)\n",
    "    \n",
    "    print('Loaded {} EAE instances ({} trigger types and {} role types) from {}'.format(\n",
    "        len(new_instances), len(trigger_type_set), len(role_type_set), file))\n",
    "    print(f\"combine cnt :{cnt}\")\n",
    "    return new_instances, type_set\n",
    "    \n",
    "    return new_instances, type_set\n",
    "if config.task == \"EAE\":\n",
    "        train_data, train_type_set = load_EAE_data(config.train_file, trainer_class.add_extra_info_fn, config)\n",
    "        dev_data, dev_type_set = load_EAE_data(config.dev_file, trainer_class.add_extra_info_fn, config)\n",
    "        test_data, test_type_set = load_EAE_data(config.test_file, trainer_class.add_extra_info_fn, config)\n",
    "        type_set = {\"trigger\": train_type_set[\"trigger\"] | dev_type_set[\"trigger\"] | test_type_set[\"trigger\"], \n",
    "                    \"role\": train_type_set[\"role\"] | dev_type_set[\"role\"] | test_type_set[\"role\"]}\n",
    "        print(\"There are {} trigger types and {} role types in total\".format(len(type_set[\"trigger\"]), len(type_set[\"role\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3003 EAE instances (2 trigger types and 16 role types) from ../data/processed_data/phee/split1/train.json\n",
      "Loaded 1011 EAE instances (2 trigger types and 16 role types) from ../data/processed_data/phee/split1/dev.json\n",
      "Loaded 1005 EAE instances (2 trigger types and 16 role types) from ../data/processed_data/phee/split1/test.json\n",
      "There are 2 trigger types and 16 role types in total\n"
     ]
    }
   ],
   "source": [
    "def load_EAE_data(file, add_extra_info_fn, config):\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as fp:\n",
    "        lines = fp.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "    \n",
    "    instances = []\n",
    "    for dt in data:\n",
    "        \n",
    "        entities = dt['entity_mentions']\n",
    "\n",
    "        event_mentions = dt['event_mentions']\n",
    "        event_mentions.sort(key=lambda x: x['trigger']['start'])\n",
    "\n",
    "        entity_map = {entity['id']: entity for entity in entities}\n",
    "        for i, event_mention in enumerate(event_mentions):\n",
    "            # trigger = (start index, end index, event type, text span)\n",
    "            trigger = (event_mention['trigger']['start'], \n",
    "                       event_mention['trigger']['end'], \n",
    "                       event_mention['event_type'], \n",
    "                       event_mention['trigger']['text'])\n",
    "\n",
    "            arguments = []\n",
    "            for arg in event_mention['arguments']:\n",
    "                mapped_entity = entity_map[arg['entity_id']]\n",
    "                \n",
    "                # argument = (start index, end index, role type, text span)\n",
    "                argument = (mapped_entity['start'], mapped_entity['end'], arg['role'], arg['text'])\n",
    "                arguments.append(argument)\n",
    "\n",
    "            arguments.sort(key=lambda x: (x[0], x[1]))\n",
    "            \n",
    "            instance = {\"doc_id\": dt[\"doc_id\"], \n",
    "                        \"wnd_id\": dt[\"wnd_id\"], \n",
    "                        \"tokens\": dt[\"tokens\"], \n",
    "                        \"text\": dt[\"text\"], \n",
    "                        \"trigger\": trigger, \n",
    "                        \"arguments\": arguments, \n",
    "                       }\n",
    "\n",
    "            instances.append(instance)\n",
    "            \n",
    "    trigger_type_set = set()\n",
    "    for instance in instances:\n",
    "        trigger_type_set.add(instance['trigger'][2])\n",
    "\n",
    "    role_type_set = set()\n",
    "    for instance in instances:\n",
    "        for argument in instance[\"arguments\"]:\n",
    "            role_type_set.add(argument[2])\n",
    "                \n",
    "    type_set = {\"trigger\": trigger_type_set, \"role\": role_type_set}\n",
    "    \n",
    "    # approach-specific preprocessing\n",
    "    new_instances = add_extra_info_fn(instances, data, config)\n",
    "    assert len(new_instances) == len(instances)\n",
    "    \n",
    "    print('Loaded {} EAE instances ({} trigger types and {} role types) from {}'.format(\n",
    "        len(new_instances), len(trigger_type_set), len(role_type_set), file))\n",
    "    \n",
    "    return new_instances, type_set\n",
    "    \n",
    "if config.task == \"EAE\":\n",
    "        train_data, train_type_set = load_EAE_data(config.train_file, trainer_class.add_extra_info_fn, config)\n",
    "        dev_data, dev_type_set = load_EAE_data(config.dev_file, trainer_class.add_extra_info_fn, config)\n",
    "        test_data, test_type_set = load_EAE_data(config.test_file, trainer_class.add_extra_info_fn, config)\n",
    "        type_set = {\"trigger\": train_type_set[\"trigger\"] | dev_type_set[\"trigger\"] | test_type_set[\"trigger\"], \n",
    "                    \"role\": train_type_set[\"role\"] | dev_type_set[\"role\"] | test_type_set[\"role\"]}\n",
    "        print(\"There are {} trigger types and {} role types in total\".format(len(type_set[\"trigger\"]), len(type_set[\"role\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.TagPrime.EAEtrainer.TagPrimeEAETrainer object at 0x0000016E471BE3D0>\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "trainer = trainer_class(config, type_set)\n",
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /roberta-base/resolve/main/vocab.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000016E4281DD90>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/roberta-base/resolve/main/vocab.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(config.pretrained_model_name, cache_dir=config.cache_dir, do_lower_case=False, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing overlapping arguments and over-length examples\n",
      "There are 3003/3003 EAE instances after removing overlapping arguments and over-length examples\n",
      "Removing overlapping arguments and over-length examples\n",
      "There are 1011/1011 EAE instances after removing overlapping arguments and over-length examples\n"
     ]
    }
   ],
   "source": [
    "def process_data( data):\n",
    "    assert tokenizer, \"Please load model and tokneizer before processing data!\"\n",
    "    \n",
    "    print(\"Removing overlapping arguments and over-length examples\")\n",
    "    \n",
    "    # greedily remove overlapping arguments\n",
    "    n_total = 0\n",
    "    new_data = []\n",
    "    for dt in data:\n",
    "        \n",
    "        n_total += 1\n",
    "        \n",
    "        if len(dt[\"tokens\"]) > config.max_length:\n",
    "            continue\n",
    "        \n",
    "        trigger = dt[\"trigger\"]\n",
    "        no_overlap_flag = np.ones((len(dt[\"tokens\"]), ), dtype=bool)\n",
    "        new_arguments = []\n",
    "        for argument in sorted(dt[\"arguments\"]):\n",
    "            start, end = argument[0], argument[1]\n",
    "            if np.all(no_overlap_flag[start:end]):\n",
    "                new_arguments.append(argument)\n",
    "                no_overlap_flag[start:end] = False\n",
    "        \n",
    "        pieces = [tokenizer.tokenize(t, is_split_into_words=True) for t in dt[\"tokens\"]]\n",
    "        token_lens = [len(p) for p in pieces] \n",
    "\n",
    "        new_dt = {\"doc_id\": dt[\"doc_id\"], \n",
    "                    \"wnd_id\": dt[\"wnd_id\"], \n",
    "                    \"tokens\": dt[\"tokens\"], \n",
    "                    \"pieces\": [p for w in pieces for p in w], \n",
    "                    \"token_lens\": token_lens, \n",
    "                    \"token_num\": len(dt[\"tokens\"]), \n",
    "                    \"text\": dt[\"text\"], \n",
    "                    \"trigger\": dt[\"trigger\"], \n",
    "                    \"arguments\": new_arguments\n",
    "                    }\n",
    "        \n",
    "        \n",
    "        new_data.append(new_dt)\n",
    "            \n",
    "    print(f\"There are {len(new_data)}/{n_total} EAE instances after removing overlapping arguments and over-length examples\")\n",
    "\n",
    "    return new_data\n",
    "internal_train_data = process_data(train_data)\n",
    "internal_dev_data = process_data(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EAEBatch_fields = ['batch_doc_id', 'batch_wnd_id', 'batch_tokens', 'batch_pieces', 'batch_token_lens', 'batch_token_num', 'batch_text', 'batch_trigger', 'batch_arguments']\n",
    "EAEBatch = namedtuple('EAEBatch', field_names=EAEBatch_fields, defaults=[None] * len(EAEBatch_fields))\n",
    "\n",
    "def EAE_collate_fn(batch):\n",
    "    return EAEBatch(\n",
    "        batch_doc_id=[instance[\"doc_id\"] for instance in batch],\n",
    "        batch_wnd_id=[instance[\"wnd_id\"] for instance in batch],\n",
    "        batch_tokens=[instance[\"tokens\"] for instance in batch], \n",
    "        batch_pieces=[instance[\"pieces\"] for instance in batch], \n",
    "        batch_token_lens=[instance[\"token_lens\"] for instance in batch], \n",
    "        batch_token_num=[instance[\"token_num\"] for instance in batch], \n",
    "        batch_text=[instance[\"text\"] for instance in batch], \n",
    "        batch_trigger=[instance[\"trigger\"] for instance in batch], \n",
    "        batch_arguments=[instance[\"arguments\"] for instance in batch], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAEBatch(batch_doc_id=['480917_1', '19249953_10', '17458405_2', '24318743_3'], batch_wnd_id=['480917_1_1', '19249953_10_1', '17458405_2_1', '24318743_3_1'], batch_tokens=[['A', 'case', 'of', 'Erythema', 'Multiforme', 'Bullosum', 'in', 'patient', 'of', 'lepromatous', 'leprosy', 'with', 'pulmonary', 'tuberculosis', 'due', 'to', 'Rifampicin', 'is', 'described', '.'], ['To', 'our', 'knowledge', ',', 'however', ',', 'this', 'is', 'the', 'first', 'case', 'report', 'of', 'a', 'possible', 'sitagliptin', '-', 'lovastatin', 'interaction', 'that', 'may', 'have', 'caused', 'rhabdomyolysis', '.'], ['Since', 'its', 'FDA', 'approval', 'in', '2002', ',', 'there', 'are', 'no', 'known', 'citations', 'of', 'ezetimibe', '-', 'induced', 'pancreatitis', '.'], ['Based', 'on', 'prior', 'data', 'suggesting', 'that', 'scheduling', 'alterations', 'of', 'platinum', 'would', 'increase', 'activity', ',', 'the', 'aim', 'of', 'the', 'present', 'study', 'was', 'to', 'assess', 'the', 'potential', 'therapeutic', 'benefit', 'of', 'phenoxodiol', '(', 'PXD', ')', ',', 'a', 'novel', 'biomodulator', 'shown', 'to', 'have', 'chemoresistance', 'reversing', 'potential', ',', 'when', 'combined', 'with', 'weekly', 'AUC2', '-', 'carboplatin', 'in', 'PROC', 'patients', '.']], batch_pieces=[['ĠA', 'Ġcase', 'Ġof', 'ĠE', 'ry', 'the', 'ma', 'ĠMult', 'iform', 'e', 'ĠBull', 'os', 'um', 'Ġin', 'Ġpatient', 'Ġof', 'Ġle', 'prom', 'at', 'ous', 'Ġle', 'pro', 'sy', 'Ġwith', 'Ġpulmonary', 'Ġtuberculosis', 'Ġdue', 'Ġto', 'ĠR', 'if', 'amp', 'ic', 'in', 'Ġis', 'Ġdescribed', 'Ġ.'], ['ĠTo', 'Ġour', 'Ġknowledge', 'Ġ,', 'Ġhowever', 'Ġ,', 'Ġthis', 'Ġis', 'Ġthe', 'Ġfirst', 'Ġcase', 'Ġreport', 'Ġof', 'Ġa', 'Ġpossible', 'Ġsit', 'ag', 'li', 'ptin', 'Ġ-', 'Ġlov', 'ast', 'atin', 'Ġinteraction', 'Ġthat', 'Ġmay', 'Ġhave', 'Ġcaused', 'Ġr', 'hab', 'dom', 'y', 'oly', 'sis', 'Ġ.'], ['ĠSince', 'Ġits', 'ĠFDA', 'Ġapproval', 'Ġin', 'Ġ2002', 'Ġ,', 'Ġthere', 'Ġare', 'Ġno', 'Ġknown', 'Ġcitations', 'Ġof', 'Ġe', 'z', 'et', 'im', 'ibe', 'Ġ-', 'Ġinduced', 'Ġpancreat', 'itis', 'Ġ.'], ['ĠBased', 'Ġon', 'Ġprior', 'Ġdata', 'Ġsuggesting', 'Ġthat', 'Ġscheduling', 'Ġalterations', 'Ġof', 'Ġplatinum', 'Ġwould', 'Ġincrease', 'Ġactivity', 'Ġ,', 'Ġthe', 'Ġaim', 'Ġof', 'Ġthe', 'Ġpresent', 'Ġstudy', 'Ġwas', 'Ġto', 'Ġassess', 'Ġthe', 'Ġpotential', 'Ġtherapeutic', 'Ġbenefit', 'Ġof', 'Ġphen', 'ox', 'od', 'iol', 'Ġ(', 'ĠP', 'X', 'D', 'Ġ)', 'Ġ,', 'Ġa', 'Ġnovel', 'Ġbiom', 'od', 'ulator', 'Ġshown', 'Ġto', 'Ġhave', 'Ġchem', 'ores', 'istance', 'Ġreversing', 'Ġpotential', 'Ġ,', 'Ġwhen', 'Ġcombined', 'Ġwith', 'Ġweekly', 'ĠA', 'UC', '2', 'Ġ-', 'Ġcarb', 'opl', 'atin', 'Ġin', 'ĠPROC', 'Ġpatients', 'Ġ.']], batch_token_lens=[[1, 1, 1, 4, 3, 3, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 5, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 3, 1, 1, 1, 1, 1, 6, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 2, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1]], batch_token_num=[20, 25, 18, 54], batch_text=['A case of Erythema Multiforme Bullosum in patient of lepromatous leprosy with pulmonary tuberculosis due to Rifampicin is described .', 'To our knowledge , however , this is the first case report of a possible sitagliptin - lovastatin interaction that may have caused rhabdomyolysis .', 'Since its FDA approval in 2002 , there are no known citations of ezetimibe - induced pancreatitis .', 'Based on prior data suggesting that scheduling alterations of platinum would increase activity , the aim of the present study was to assess the potential therapeutic benefit of phenoxodiol ( PXD ) , a novel biomodulator shown to have chemoresistance reversing potential , when combined with weekly AUC2 - carboplatin in PROC patients .'], batch_trigger=[(14, 16, 'Adverse_event', 'due to'), (22, 23, 'Adverse_event', 'caused'), (15, 16, 'Adverse_event', 'induced'), (22, 23, 'Potential_therapeutic_event', 'assess')], batch_arguments=[[(3, 6, 'Effect', 'Erythema Multiforme Bullosum'), (7, 14, 'Subject', 'patient of lepromatous leprosy with pulmonary tuberculosis'), (16, 17, 'Treatment', 'Rifampicin')], [(15, 16, 'Combination_Drug', 'sitagliptin'), (17, 18, 'Combination_Drug', 'lovastatin'), (23, 24, 'Effect', 'rhabdomyolysis')], [(13, 14, 'Treatment', 'ezetimibe'), (16, 17, 'Effect', 'pancreatitis')], [(24, 27, 'Effect', 'potential therapeutic benefit'), (28, 29, 'Combination_Drug', 'phenoxodiol'), (46, 47, 'Treatment_Freq', 'weekly'), (49, 50, 'Combination_Drug', 'carboplatin'), (51, 52, 'Treatment_Disorder', 'PROC')]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pprint\n",
    "train = DataLoader(internal_train_data, batch_size=4, \n",
    "                                                         shuffle=True, drop_last=False, collate_fn=EAE_collate_fn)\n",
    "batch = next(iter(train))\n",
    "pprint.pprint(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trigger': {'Adverse_event', 'Potential_therapeutic_event'},\n",
       " 'role': {'Combination_Drug',\n",
       "  'Effect',\n",
       "  'Subject',\n",
       "  'Subject_Age',\n",
       "  'Subject_Disorder',\n",
       "  'Subject_Gender',\n",
       "  'Subject_Population',\n",
       "  'Subject_Race',\n",
       "  'Treatment',\n",
       "  'Treatment_Disorder',\n",
       "  'Treatment_Dosage',\n",
       "  'Treatment_Drug',\n",
       "  'Treatment_Duration',\n",
       "  'Treatment_Freq',\n",
       "  'Treatment_Route',\n",
       "  'Treatment_Time_elapsed'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tagging_vocab():\n",
    "        prefix = ['B', 'I']\n",
    "        trigger_label_stoi = {'O': 0}\n",
    "        for t in sorted(type_set[\"trigger\"]):\n",
    "            for p in prefix:\n",
    "                trigger_label_stoi['{}-{}'.format(p, t)] = len(trigger_label_stoi)\n",
    "\n",
    "        role_label_stoi = {'O': 0}\n",
    "        for t in sorted(type_set[\"role\"]):\n",
    "            for p in prefix:\n",
    "                role_label_stoi['{}-{}'.format(p, t)] = len(role_label_stoi)\n",
    "        \n",
    "        if config.priming_type == \"condition+relation\":\n",
    "            label_stoi = {\"trigger\": trigger_label_stoi, \"role\": {\"O\": 0, \"B-Pred\": 1, \"I-Pred\": 2}}\n",
    "        else:\n",
    "            label_stoi = {\"trigger\": trigger_label_stoi, \"role\": role_label_stoi}\n",
    "        \n",
    "        trigger_type_stoi = {t: i for i, t in enumerate(sorted(type_set[\"trigger\"]))}\n",
    "        role_type_stoi = {t: i for i, t in enumerate(sorted(type_set[\"role\"]))}\n",
    "        type_stoi = {\"trigger\": trigger_type_stoi, \"role\": role_type_stoi}\n",
    "        return label_stoi , type_stoi\n",
    "label_stoi , type_stoi = generate_tagging_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trigger': {'O': 0, 'B-Adverse_event': 1, 'I-Adverse_event': 2, 'B-Potential_therapeutic_event': 3, 'I-Potential_therapeutic_event': 4}, 'role': {'O': 0, 'B-Combination_Drug': 1, 'I-Combination_Drug': 2, 'B-Effect': 3, 'I-Effect': 4, 'B-Subject': 5, 'I-Subject': 6, 'B-Subject_Age': 7, 'I-Subject_Age': 8, 'B-Subject_Disorder': 9, 'I-Subject_Disorder': 10, 'B-Subject_Gender': 11, 'I-Subject_Gender': 12, 'B-Subject_Population': 13, 'I-Subject_Population': 14, 'B-Subject_Race': 15, 'I-Subject_Race': 16, 'B-Treatment': 17, 'I-Treatment': 18, 'B-Treatment_Disorder': 19, 'I-Treatment_Disorder': 20, 'B-Treatment_Dosage': 21, 'I-Treatment_Dosage': 22, 'B-Treatment_Drug': 23, 'I-Treatment_Drug': 24, 'B-Treatment_Duration': 25, 'I-Treatment_Duration': 26, 'B-Treatment_Freq': 27, 'I-Treatment_Freq': 28, 'B-Treatment_Route': 29, 'I-Treatment_Route': 30, 'B-Treatment_Time_elapsed': 31, 'I-Treatment_Time_elapsed': 32}}\n"
     ]
    }
   ],
   "source": [
    "print(label_stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-Combination_Drug': 1,\n",
       " 'I-Combination_Drug': 2,\n",
       " 'B-Effect': 3,\n",
       " 'I-Effect': 4,\n",
       " 'B-Subject': 5,\n",
       " 'I-Subject': 6,\n",
       " 'B-Subject_Age': 7,\n",
       " 'I-Subject_Age': 8,\n",
       " 'B-Subject_Disorder': 9,\n",
       " 'I-Subject_Disorder': 10,\n",
       " 'B-Subject_Gender': 11,\n",
       " 'I-Subject_Gender': 12,\n",
       " 'B-Subject_Population': 13,\n",
       " 'I-Subject_Population': 14,\n",
       " 'B-Subject_Race': 15,\n",
       " 'I-Subject_Race': 16,\n",
       " 'B-Treatment': 17,\n",
       " 'I-Treatment': 18,\n",
       " 'B-Treatment_Disorder': 19,\n",
       " 'I-Treatment_Disorder': 20,\n",
       " 'B-Treatment_Dosage': 21,\n",
       " 'I-Treatment_Dosage': 22,\n",
       " 'B-Treatment_Drug': 23,\n",
       " 'I-Treatment_Drug': 24,\n",
       " 'B-Treatment_Duration': 25,\n",
       " 'I-Treatment_Duration': 26,\n",
       " 'B-Treatment_Freq': 27,\n",
       " 'I-Treatment_Freq': 28,\n",
       " 'B-Treatment_Route': 29,\n",
       " 'I-Treatment_Route': 30,\n",
       " 'B-Treatment_Time_elapsed': 31,\n",
       " 'I-Treatment_Time_elapsed': 32}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_stoi[\"role\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trigger': {'Adverse_event': 0, 'Potential_therapeutic_event': 1}, 'role': {'Combination_Drug': 0, 'Effect': 1, 'Subject': 2, 'Subject_Age': 3, 'Subject_Disorder': 4, 'Subject_Gender': 5, 'Subject_Population': 6, 'Subject_Race': 7, 'Treatment': 8, 'Treatment_Disorder': 9, 'Treatment_Dosage': 10, 'Treatment_Drug': 11, 'Treatment_Duration': 12, 'Treatment_Freq': 13, 'Treatment_Route': 14, 'Treatment_Time_elapsed': 15}}\n"
     ]
    }
   ],
   "source": [
    "print(type_stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_role_seqlabels( roles, token_num, specify_role=None, use_unified_label=False):\n",
    "    labels = ['O'] * token_num\n",
    "    count = 0\n",
    "    for role in roles:\n",
    "        start, end = role[0], role[1]\n",
    "        if end > token_num:\n",
    "            continue\n",
    "        role_type = role[2]\n",
    "\n",
    "        if specify_role is not None:\n",
    "            if role_type != specify_role:\n",
    "                continue\n",
    "        # 是否至少有一个值为True，如果是则返回True，否则返回False\n",
    "        if any([labels[i] != 'O' for i in range(start, end)]):\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "        if (specify_role is not None) and use_unified_label:\n",
    "            labels[start] = 'B-{}'.format(\"Pred\")\n",
    "            for i in range(start + 1, end):\n",
    "                labels[i] = 'I-{}'.format(\"Pred\")\n",
    "        else:\n",
    "            labels[start] = 'B-{}'.format(role_type)\n",
    "            for i in range(start + 1, end):\n",
    "                labels[i] = 'I-{}'.format(role_type)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 6, 'Effect', 'Erythema Multiforme Bullosum'),\n",
       "  (7,\n",
       "   14,\n",
       "   'Subject',\n",
       "   'patient of lepromatous leprosy with pulmonary tuberculosis'),\n",
       "  (16, 17, 'Treatment', 'Rifampicin')],\n",
       " [(15, 16, 'Combination_Drug', 'sitagliptin'),\n",
       "  (17, 18, 'Combination_Drug', 'lovastatin'),\n",
       "  (23, 24, 'Effect', 'rhabdomyolysis')],\n",
       " [(13, 14, 'Treatment', 'ezetimibe'), (16, 17, 'Effect', 'pancreatitis')],\n",
       " [(24, 27, 'Effect', 'potential therapeutic benefit'),\n",
       "  (28, 29, 'Combination_Drug', 'phenoxodiol'),\n",
       "  (46, 47, 'Treatment_Freq', 'weekly'),\n",
       "  (49, 50, 'Combination_Drug', 'carboplatin'),\n",
       "  (51, 52, 'Treatment_Disorder', 'PROC')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern import event_type_tags,event_description\n",
    "def process_data(batch):\n",
    "        enc_idxs = []\n",
    "        pro_idxs = []\n",
    "        enc_attn_pro = []\n",
    "        enc_attn = []\n",
    "        role_seqidxs = []\n",
    "        trigger_types = []\n",
    "        token_lens = []\n",
    "        token_nums = []\n",
    "        triggers = []\n",
    "        max_token_num = max(batch.batch_token_num)\n",
    "        \n",
    "        for tokens, pieces, trigger, arguments, token_len, token_num in zip(batch.batch_tokens, batch.batch_pieces, batch.batch_trigger, \n",
    "                                                                      batch.batch_arguments, batch.batch_token_lens, batch.batch_token_num):\n",
    "            \n",
    "        \n",
    "            event_type_map = event_type_tags[config.dataset]\n",
    "\n",
    "            prompt = \"{} {} {} {} {}\".format(event_type_map[trigger[2]], \n",
    "                                             tokenizer.sep_token, trigger[3],\n",
    "                                             tokenizer.sep_token,event_description[config.dataset][trigger[2]][\"event description\"])\n",
    "            \n",
    "            prompt_id = tokenizer.encode(prompt, add_special_tokens=False,is_split_into_words = False) \n",
    "             \n",
    "            piece_id = tokenizer.convert_tokens_to_ids(pieces)\n",
    "            \n",
    "            enc_idx = [tokenizer.convert_tokens_to_ids(tokenizer.bos_token)] + piece_id + [tokenizer.convert_tokens_to_ids(tokenizer.eos_token)]\n",
    "            prompt_idx = [tokenizer.convert_tokens_to_ids(tokenizer.bos_token)] + prompt_id + [tokenizer.convert_tokens_to_ids(tokenizer.eos_token)]\n",
    "            \n",
    "            # enc_idx = enc_idx[:base_config.max_position_embeddings-2]\n",
    "            # prompt_idx = prompt_idx[:base_config.max_position_embeddings-2]\n",
    "            \n",
    "            pro_idxs.append(prompt_idx)\n",
    "            enc_idxs.append(enc_idx)\n",
    "\n",
    "            enc_attn_pro.append([1]*len(prompt_idx))\n",
    "            enc_attn.append([1]*len(enc_idx))  \n",
    "\n",
    "            role_seq = get_role_seqlabels(arguments, len(tokens))\n",
    "            trigger_types.append(type_stoi[\"trigger\"][trigger[2]])\n",
    "            token_lens.append(token_len)\n",
    "            token_nums.append(token_num)\n",
    "            triggers.append(trigger)\n",
    "            if config.use_crf:\n",
    "                role_seqidxs.append([label_stoi[\"role\"][s] for s in role_seq] + [0] * (max_token_num-len(tokens)))\n",
    "            else:\n",
    "                role_seqidxs.append([label_stoi[\"role\"][s] for s in role_seq] + [-100] * (max_token_num-len(tokens)))\n",
    "                    \n",
    "        max_len = max([len(enc_idx) for enc_idx in enc_idxs])\n",
    "        enc_idxs = torch.LongTensor([enc_idx + [tokenizer.convert_tokens_to_ids(tokenizer.pad_token)]*(max_len-len(enc_idx)) for enc_idx in enc_idxs])\n",
    "        enc_attn = torch.LongTensor([enc_att + [0]*(max_len-len(enc_att)) for enc_att in enc_attn])\n",
    "        \n",
    "        max_len = max([len(prompt_idx) for prompt_idx in pro_idxs])\n",
    "        pro_idxs = torch.LongTensor([prompt_idx + [tokenizer.convert_tokens_to_ids(tokenizer.pad_token)]*(max_len-len(prompt_idx)) for prompt_idx in pro_idxs])\n",
    "        enc_attn_pro = torch.LongTensor([enc_attn_pr + [0]*(max_len-len(enc_attn_pr)) for enc_attn_pr in enc_attn_pro])\n",
    "\n",
    "        \n",
    "        trigger_types = torch.LongTensor(trigger_types)\n",
    "        role_seqidxs = torch.LongTensor(role_seqidxs)\n",
    "        return enc_idxs, enc_attn, role_seqidxs, trigger_types, token_lens, torch.LongTensor(token_nums), triggers,pro_idxs,enc_attn_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_idxs, enc_attn, role_seqidxs, trigger_types, token_lens, token_nums, triggers ,pro_idxs,enc_attn_pro = process_data(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 11, 27, 19]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch_token_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25]) torch.Size([4, 25])\n"
     ]
    }
   ],
   "source": [
    "print(pro_idxs.size(),enc_attn_pro.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /roberta-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000016E4D11A610>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/roberta-base/resolve/main/config.json\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /roberta-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000016E4D25B550>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/roberta-base/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "base_model = RobertaModel.from_pretrained(config.pretrained_model_name, \n",
    "                                                           cache_dir=config.cache_dir, \n",
    "                                                           output_hidden_states=True)\n",
    "base_config = RobertaConfig.from_pretrained(config.pretrained_model_name, \n",
    "                                                             cache_dir=config.cache_dir)\n",
    "base_model_dim = base_config.hidden_size\n",
    "print(base_model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lens_to_idxs( token_lens):\n",
    "        \"\"\"Map token lengths to a word piece index matrix (for torch.gather) and a\n",
    "        mask tensor.\n",
    "        For example (only show a sequence instead of a batch):\n",
    "        token lengths: [1,1,1,3,1]\n",
    "        =>\n",
    "        indices: [[0,0,0], [1,0,0], [2,0,0], [3,4,5], [6,0,0]]\n",
    "        masks: [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0],\n",
    "                [0.33, 0.33, 0.33], [1.0, 0.0, 0.0]]\n",
    "        Next, we use torch.gather() to select vectors of word pieces for each token,\n",
    "        and average them as follows (incomplete code):\n",
    "        outputs = torch.gather(bert_outputs, 1, indices) * masks\n",
    "        outputs = bert_outputs.view(batch_size, seq_len, -1, self.bert_dim)\n",
    "        outputs = bert_outputs.sum(2)\n",
    "        :param token_lens (list): token lengths.\n",
    "        :return: a index matrix and a mask tensor.\n",
    "        \"\"\"\n",
    "        max_token_num = max([len(x) for x in token_lens])\n",
    "        max_token_len = max([max(x) for x in token_lens])\n",
    "        idxs, masks = [], []\n",
    "        for seq_token_lens in token_lens:\n",
    "            seq_idxs, seq_masks = [], []\n",
    "            offset = 0\n",
    "            for token_len in seq_token_lens:\n",
    "                seq_idxs.extend([i + offset for i in range(token_len)]\n",
    "                                + [-1] * (max_token_len - token_len))\n",
    "                seq_masks.extend([1.0 / token_len] * token_len\n",
    "                                 + [0.0] * (max_token_len - token_len))\n",
    "                offset += token_len\n",
    "            seq_idxs.extend([-1] * max_token_len * (max_token_num - len(seq_token_lens)))\n",
    "            seq_masks.extend([0.0] * max_token_len * (max_token_num - len(seq_token_lens)))\n",
    "            idxs.append(seq_idxs)\n",
    "            masks.append(seq_masks)\n",
    "        return idxs, masks, max_token_num, max_token_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dropout = nn.Dropout(p=config.base_model_dropout)\n",
    "def encode(piece_idxs, attention_masks, token_lens):\n",
    "    \"\"\"Encode input sequences with BERT\n",
    "    :param piece_idxs (LongTensor): word pieces indices\n",
    "    :param attention_masks (FloatTensor): attention mask\n",
    "    :param token_lens (list): token lengths\n",
    "    \"\"\"\n",
    "    batch_size, _ = piece_idxs.size()\n",
    "    all_base_model_outputs = base_model(piece_idxs, attention_mask=attention_masks)\n",
    "    base_model_outputs = all_base_model_outputs[0]\n",
    "    if config.multi_piece_strategy == 'first':\n",
    "        # select the first piece for multi-piece words\n",
    "        offsets = token_lens_to_offsets(token_lens)\n",
    "        offsets = piece_idxs.new(offsets) # batch x max_token_num\n",
    "        # + 1 because the first vector is for [CLS]\n",
    "        offsets = offsets.unsqueeze(-1).expand(batch_size, -1, bert_dim) + 1\n",
    "        base_model_outputs = torch.gather(base_model_outputs, 1, offsets)\n",
    "    elif config.multi_piece_strategy == 'average':\n",
    "        # average all pieces for multi-piece words\n",
    "        idxs, masks, token_num, token_len = token_lens_to_idxs(token_lens)\n",
    "        idxs = piece_idxs.new(idxs).unsqueeze(-1).expand(batch_size, -1, base_model_dim) + 1\n",
    "        masks = base_model_outputs.new(masks).unsqueeze(-1)\n",
    "        base_model_outputs = torch.gather(base_model_outputs, 1, idxs) * masks\n",
    "        base_model_outputs = base_model_outputs.view(batch_size, token_num, token_len, base_model_dim)\n",
    "        base_model_outputs = base_model_outputs.sum(2)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown multi-piece token handling strategy: {config.multi_piece_strategy}')\n",
    "    base_model_outputs = base_model_dropout(base_model_outputs)\n",
    "    return base_model_outputs\n",
    "base_model_outputs = encode(enc_idxs, enc_attn, token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_model_outputs = base_model(pro_idxs, attention_mask=enc_attn_pro)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    \"\"\"cross attention between input text and prompt\"\"\"\n",
    "    def __init__(self,d_model,d_k,d_v):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k \n",
    "        self.W_Q = nn.Linear(d_model, d_k , bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k , bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v , bias=False)\n",
    "        self.fc = nn.Linear( d_v, d_model, bias=False)\n",
    "    def forward(self, input_Q, input_K, input_V,attn_mask):\n",
    "        '''\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        seq_len = input_Q.size(1)\n",
    "        Q = self.W_Q(input_Q) # Q: [batch_size, len_q, d_k]\n",
    "        K = self.W_K(input_K) # K: [batch_size, len_k, d_k]\n",
    "        V = self.W_V(input_V) # V: [batch_size, len_v(=len_k), d_v]\n",
    "\n",
    "        scores = torch.matmul(Q,K.transpose(-1, -2))/np.sqrt(self.d_k)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1,seq_len,1)\n",
    "        scores.masked_fill_(attn_mask==0, -1e9)\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        output = torch.matmul(attn, V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dim = base_config.hidden_size\n",
    "cross_att = CrossAttention(d_model = base_model_dim,\n",
    "                            d_k = base_model_dim ,\n",
    "                            d_v = base_model_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten = cross_att(base_model_outputs,pro_model_outputs,pro_model_outputs,enc_attn_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27, 768])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 29, 768])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27, 1536])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((base_model_outputs,atten),-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
