{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "# from argparse import ArgumentParser\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "# import stanza\n",
    "# import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docs(path):\n",
    "    all_objs = []\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        ## 检查文件是不是json格式\n",
    "        if not file.endswith(\"json\"):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(path, file)) as fp:\n",
    "                obj = json.load(fp)\n",
    "        except:\n",
    "            continue\n",
    "        all_objs.append(obj)\n",
    "    \n",
    "    return all_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_folder = './annotation/'\n",
    "objs = read_docs(in_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(objs, split):\n",
    "    \n",
    "    with open(os.path.join(split, \"train.txt\")) as fp:\n",
    "        lines = fp.readlines()\n",
    "        train_doc_ids = set([l.strip() for l in lines])\n",
    "        \n",
    "    with open(os.path.join(split, \"dev.txt\")) as fp:\n",
    "        lines = fp.readlines()\n",
    "        dev_doc_ids = set([l.strip() for l in lines])\n",
    "        \n",
    "    with open(os.path.join(split, \"test.txt\")) as fp:\n",
    "        lines = fp.readlines()\n",
    "        test_doc_ids = set([l.strip() for l in lines])\n",
    "\n",
    "    train_objs = []\n",
    "    dev_objs = []\n",
    "    test_objs = []\n",
    "    \n",
    "    for obj in objs:\n",
    "        if obj[\"sourcefile\"] in train_doc_ids:\n",
    "            train_objs.append(obj)\n",
    "        if obj[\"sourcefile\"] in dev_doc_ids:\n",
    "            dev_objs.append(obj)\n",
    "        if obj[\"sourcefile\"] in test_doc_ids:\n",
    "            test_objs.append(obj)\n",
    "    \n",
    "    train_objs.sort(key=lambda x: x[\"sourcefile\"])\n",
    "    dev_objs.sort(key=lambda x: x[\"sourcefile\"])\n",
    "    test_objs.sort(key=lambda x: x[\"sourcefile\"])\n",
    "    \n",
    "    return train_objs, dev_objs, test_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = './split1/'\n",
    "train_objs, dev_objs, test_objs = get_split(objs, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 149 149\n"
     ]
    }
   ],
   "source": [
    "print(len(train_objs),len(dev_objs),len(test_objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "n_drop_event = 0\n",
    "n_drop_arg = 0\n",
    "with open(\"token_map.json\") as fp:\n",
    "    token_map = json.load(fp)\n",
    "\n",
    "with open(\"seg_map.json\") as fp:\n",
    "    seg_map = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = train_objs[0]\n",
    "text_tokens = [[obj[\"content\"][si:ei] for si, ei in sent] for sent in token_map[obj[\"sourcefile\"]]]\n",
    "'''\n",
    "token_map:列表形式，第一层为每个句子，第二层为每个句子内部分词\n",
    "text_tokens:列表形式，第一层代表句子，第二层为句子分词\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[25, 44, 25, 25, 33, 9, 19, 10, 15, 15, 19, 3]\n"
     ]
    }
   ],
   "source": [
    "n_sent = len(text_tokens)\n",
    "print(n_sent)\n",
    "sent_lens = [len(s) for s in text_tokens]\n",
    "print(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 12]] 1\n"
     ]
    }
   ],
   "source": [
    "sents = seg_map[obj[\"sourcefile\"]]\n",
    "n_seg = len(sents)\n",
    "print(sents,n_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mentions = defaultdict(list)\n",
    "event_mentions = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_offsets = token_map[obj[\"sourcefile\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_offsets = []\n",
    "'''\n",
    "将所有句子以及分词整合到一个列表中\n",
    "'''\n",
    "for si, ei in sents:\n",
    "            segs = []\n",
    "            for i in range(si, ei):\n",
    "                segs.extend(sent_offsets[i])\n",
    "            seg_offsets.append(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hopper': [{'relation': 'Same',\n",
       "   'index': 0,\n",
       "   'events': [{'nugget': {'startOffset': 273,\n",
       "      'index': 'T8',\n",
       "      'endOffset': 290,\n",
       "      'text': 'had been accessed'},\n",
       "     'subtype': 'Databreach',\n",
       "     'argument': [{'startOffset': 262,\n",
       "       'index': 'T10',\n",
       "       'endOffset': 271,\n",
       "       'role': {'type': 'Compromised-Data'},\n",
       "       'type': 'PII',\n",
       "       'text': 'addresses'},\n",
       "      {'startOffset': 238,\n",
       "       'index': 'T9',\n",
       "       'endOffset': 257,\n",
       "       'role': {'type': 'Compromised-Data'},\n",
       "       'type': 'PII',\n",
       "       'text': 'their phone numbers'},\n",
       "      {'startOffset': 215,\n",
       "       'index': 'T11',\n",
       "       'endOffset': 226,\n",
       "       'role': {'type': 'Compromised-Data'},\n",
       "       'type': 'Data',\n",
       "       'text': 'information'},\n",
       "      {'startOffset': 189,\n",
       "       'index': 'T12',\n",
       "       'endOffset': 194,\n",
       "       'role': {'type': 'Victim'},\n",
       "       'external_reference': {'wikidataid': 'Q467'},\n",
       "       'type': 'Person',\n",
       "       'text': 'women'}],\n",
       "     'index': 'E3',\n",
       "     'realis': 'Actual',\n",
       "     'type': 'Attack'},\n",
       "    {'nugget': {'startOffset': 324,\n",
       "      'index': 'T6',\n",
       "      'endOffset': 332,\n",
       "      'text': 'breached'},\n",
       "     'subtype': 'Databreach',\n",
       "     'argument': [{'startOffset': 300,\n",
       "       'index': 'T7',\n",
       "       'endOffset': 319,\n",
       "       'role': {'type': 'Attacker'},\n",
       "       'type': 'Person',\n",
       "       'text': 'the member of staff'}],\n",
       "     'index': 'E2',\n",
       "     'realis': 'Actual',\n",
       "     'type': 'Attack'},\n",
       "    {'nugget': {'startOffset': 97,\n",
       "      'index': 'T1',\n",
       "      'endOffset': 105,\n",
       "      'text': 'accessed'},\n",
       "     'subtype': 'Databreach',\n",
       "     'argument': [{'startOffset': 74,\n",
       "       'index': 'T4',\n",
       "       'endOffset': 96,\n",
       "       'role': {'type': 'Compromised-Data'},\n",
       "       'type': 'PII',\n",
       "       'text': 'their personal details'},\n",
       "      {'startOffset': 109,\n",
       "       'index': 'T2',\n",
       "       'endOffset': 126,\n",
       "       'role': {'type': 'Attacker'},\n",
       "       'type': 'Person',\n",
       "       'text': 'a member of staff'},\n",
       "      {'startOffset': 130,\n",
       "       'index': 'T3',\n",
       "       'endOffset': 149,\n",
       "       'role': {'type': 'Victim'},\n",
       "       'external_reference': {'dbpediaURI': 'http://dbpedia.org/resource/University_Hospital_Crosshouse',\n",
       "        'wikidataid': 'Q7894766'},\n",
       "       'type': 'Organization',\n",
       "       'text': 'Crosshouse Hospital'},\n",
       "      {'startOffset': 56,\n",
       "       'index': 'T5',\n",
       "       'endOffset': 64,\n",
       "       'role': {'type': 'Victim'},\n",
       "       'external_reference': {'wikidataid': 'Q181600'},\n",
       "       'type': 'Person',\n",
       "       'text': 'patients'}],\n",
       "     'index': 'E1',\n",
       "     'realis': 'Actual',\n",
       "     'type': 'Attack'},\n",
       "    {'nugget': {'startOffset': 407,\n",
       "      'index': 'T13',\n",
       "      'endOffset': 417,\n",
       "      'text': 'The breach'},\n",
       "     'subtype': 'Databreach',\n",
       "     'argument': [{'startOffset': 435,\n",
       "       'index': 'T16',\n",
       "       'endOffset': 446,\n",
       "       'role': {'type': 'Compromised-Data'},\n",
       "       'type': 'Data',\n",
       "       'text': 'information'},\n",
       "      {'startOffset': 455,\n",
       "       'index': 'T14',\n",
       "       'endOffset': 487,\n",
       "       'role': {'type': 'Victim'},\n",
       "       'type': 'System',\n",
       "       'text': 'the Radiology Information System'},\n",
       "      {'startOffset': 492,\n",
       "       'index': 'T15',\n",
       "       'endOffset': 500,\n",
       "       'role': {'type': 'Victim'},\n",
       "       'external_reference': {'wikidataid': 'Q181600'},\n",
       "       'type': 'Person',\n",
       "       'text': 'patients'}],\n",
       "     'index': 'E4',\n",
       "     'realis': 'Actual',\n",
       "     'type': 'Attack'},\n",
       "    {'nugget': {'startOffset': 615,\n",
       "      'index': 'T17',\n",
       "      'endOffset': 625,\n",
       "      'text': 'the breach'},\n",
       "     'subtype': 'Databreach',\n",
       "     'argument': [{'startOffset': 643,\n",
       "       'index': 'T18',\n",
       "       'endOffset': 683,\n",
       "       'role': {'type': 'Time'},\n",
       "       'type': 'Time',\n",
       "       'text': 'between April and September of this year'},\n",
       "      {'startOffset': 557,\n",
       "       'index': 'T23',\n",
       "       'endOffset': 574,\n",
       "       'role': {'type': 'Attacker'},\n",
       "       'type': 'Person',\n",
       "       'text': 'A member of staff'}],\n",
       "     'index': 'E5',\n",
       "     'realis': 'Actual',\n",
       "     'type': 'Attack'},\n",
       "    {'nugget': {'startOffset': 835,\n",
       "      'index': 'T21',\n",
       "      'endOffset': 844,\n",
       "      'text': 'accessing'},\n",
       "     'subtype': 'Databreach',\n",
       "     'argument': [{'startOffset': 801,\n",
       "       'index': 'T20',\n",
       "       'endOffset': 818,\n",
       "       'role': {'type': 'Attacker'},\n",
       "       'type': 'Person',\n",
       "       'text': 'a member of staff'},\n",
       "      {'startOffset': 845,\n",
       "       'index': 'T22',\n",
       "       'endOffset': 860,\n",
       "       'role': {'type': 'Compromised-Data'},\n",
       "       'type': 'PII',\n",
       "       'text': 'patient records'}],\n",
       "     'index': 'E6',\n",
       "     'realis': 'Actual',\n",
       "     'type': 'Attack'}]}]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj['cyberevent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relation': 'Same',\n",
       " 'index': 0,\n",
       " 'events': [{'nugget': {'startOffset': 273,\n",
       "    'index': 'T8',\n",
       "    'endOffset': 290,\n",
       "    'text': 'had been accessed'},\n",
       "   'subtype': 'Databreach',\n",
       "   'argument': [{'startOffset': 262,\n",
       "     'index': 'T10',\n",
       "     'endOffset': 271,\n",
       "     'role': {'type': 'Compromised-Data'},\n",
       "     'type': 'PII',\n",
       "     'text': 'addresses'},\n",
       "    {'startOffset': 238,\n",
       "     'index': 'T9',\n",
       "     'endOffset': 257,\n",
       "     'role': {'type': 'Compromised-Data'},\n",
       "     'type': 'PII',\n",
       "     'text': 'their phone numbers'},\n",
       "    {'startOffset': 215,\n",
       "     'index': 'T11',\n",
       "     'endOffset': 226,\n",
       "     'role': {'type': 'Compromised-Data'},\n",
       "     'type': 'Data',\n",
       "     'text': 'information'},\n",
       "    {'startOffset': 189,\n",
       "     'index': 'T12',\n",
       "     'endOffset': 194,\n",
       "     'role': {'type': 'Victim'},\n",
       "     'external_reference': {'wikidataid': 'Q467'},\n",
       "     'type': 'Person',\n",
       "     'text': 'women'}],\n",
       "   'index': 'E3',\n",
       "   'realis': 'Actual',\n",
       "   'type': 'Attack'},\n",
       "  {'nugget': {'startOffset': 324,\n",
       "    'index': 'T6',\n",
       "    'endOffset': 332,\n",
       "    'text': 'breached'},\n",
       "   'subtype': 'Databreach',\n",
       "   'argument': [{'startOffset': 300,\n",
       "     'index': 'T7',\n",
       "     'endOffset': 319,\n",
       "     'role': {'type': 'Attacker'},\n",
       "     'type': 'Person',\n",
       "     'text': 'the member of staff'}],\n",
       "   'index': 'E2',\n",
       "   'realis': 'Actual',\n",
       "   'type': 'Attack'},\n",
       "  {'nugget': {'startOffset': 97,\n",
       "    'index': 'T1',\n",
       "    'endOffset': 105,\n",
       "    'text': 'accessed'},\n",
       "   'subtype': 'Databreach',\n",
       "   'argument': [{'startOffset': 74,\n",
       "     'index': 'T4',\n",
       "     'endOffset': 96,\n",
       "     'role': {'type': 'Compromised-Data'},\n",
       "     'type': 'PII',\n",
       "     'text': 'their personal details'},\n",
       "    {'startOffset': 109,\n",
       "     'index': 'T2',\n",
       "     'endOffset': 126,\n",
       "     'role': {'type': 'Attacker'},\n",
       "     'type': 'Person',\n",
       "     'text': 'a member of staff'},\n",
       "    {'startOffset': 130,\n",
       "     'index': 'T3',\n",
       "     'endOffset': 149,\n",
       "     'role': {'type': 'Victim'},\n",
       "     'external_reference': {'dbpediaURI': 'http://dbpedia.org/resource/University_Hospital_Crosshouse',\n",
       "      'wikidataid': 'Q7894766'},\n",
       "     'type': 'Organization',\n",
       "     'text': 'Crosshouse Hospital'},\n",
       "    {'startOffset': 56,\n",
       "     'index': 'T5',\n",
       "     'endOffset': 64,\n",
       "     'role': {'type': 'Victim'},\n",
       "     'external_reference': {'wikidataid': 'Q181600'},\n",
       "     'type': 'Person',\n",
       "     'text': 'patients'}],\n",
       "   'index': 'E1',\n",
       "   'realis': 'Actual',\n",
       "   'type': 'Attack'},\n",
       "  {'nugget': {'startOffset': 407,\n",
       "    'index': 'T13',\n",
       "    'endOffset': 417,\n",
       "    'text': 'The breach'},\n",
       "   'subtype': 'Databreach',\n",
       "   'argument': [{'startOffset': 435,\n",
       "     'index': 'T16',\n",
       "     'endOffset': 446,\n",
       "     'role': {'type': 'Compromised-Data'},\n",
       "     'type': 'Data',\n",
       "     'text': 'information'},\n",
       "    {'startOffset': 455,\n",
       "     'index': 'T14',\n",
       "     'endOffset': 487,\n",
       "     'role': {'type': 'Victim'},\n",
       "     'type': 'System',\n",
       "     'text': 'the Radiology Information System'},\n",
       "    {'startOffset': 492,\n",
       "     'index': 'T15',\n",
       "     'endOffset': 500,\n",
       "     'role': {'type': 'Victim'},\n",
       "     'external_reference': {'wikidataid': 'Q181600'},\n",
       "     'type': 'Person',\n",
       "     'text': 'patients'}],\n",
       "   'index': 'E4',\n",
       "   'realis': 'Actual',\n",
       "   'type': 'Attack'},\n",
       "  {'nugget': {'startOffset': 615,\n",
       "    'index': 'T17',\n",
       "    'endOffset': 625,\n",
       "    'text': 'the breach'},\n",
       "   'subtype': 'Databreach',\n",
       "   'argument': [{'startOffset': 643,\n",
       "     'index': 'T18',\n",
       "     'endOffset': 683,\n",
       "     'role': {'type': 'Time'},\n",
       "     'type': 'Time',\n",
       "     'text': 'between April and September of this year'},\n",
       "    {'startOffset': 557,\n",
       "     'index': 'T23',\n",
       "     'endOffset': 574,\n",
       "     'role': {'type': 'Attacker'},\n",
       "     'type': 'Person',\n",
       "     'text': 'A member of staff'}],\n",
       "   'index': 'E5',\n",
       "   'realis': 'Actual',\n",
       "   'type': 'Attack'},\n",
       "  {'nugget': {'startOffset': 835,\n",
       "    'index': 'T21',\n",
       "    'endOffset': 844,\n",
       "    'text': 'accessing'},\n",
       "   'subtype': 'Databreach',\n",
       "   'argument': [{'startOffset': 801,\n",
       "     'index': 'T20',\n",
       "     'endOffset': 818,\n",
       "     'role': {'type': 'Attacker'},\n",
       "     'type': 'Person',\n",
       "     'text': 'a member of staff'},\n",
       "    {'startOffset': 845,\n",
       "     'index': 'T22',\n",
       "     'endOffset': 860,\n",
       "     'role': {'type': 'Compromised-Data'},\n",
       "     'type': 'PII',\n",
       "     'text': 'patient records'}],\n",
       "   'index': 'E6',\n",
       "   'realis': 'Actual',\n",
       "   'type': 'Attack'}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopper = obj['cyberevent']['hopper'][0]\n",
    "hopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nugget': {'startOffset': 273, 'index': 'T8', 'endOffset': 290, 'text': 'had been accessed'}, 'subtype': 'Databreach', 'argument': [{'startOffset': 262, 'index': 'T10', 'endOffset': 271, 'role': {'type': 'Compromised-Data'}, 'type': 'PII', 'text': 'addresses'}, {'startOffset': 238, 'index': 'T9', 'endOffset': 257, 'role': {'type': 'Compromised-Data'}, 'type': 'PII', 'text': 'their phone numbers'}, {'startOffset': 215, 'index': 'T11', 'endOffset': 226, 'role': {'type': 'Compromised-Data'}, 'type': 'Data', 'text': 'information'}, {'startOffset': 189, 'index': 'T12', 'endOffset': 194, 'role': {'type': 'Victim'}, 'external_reference': {'wikidataid': 'Q467'}, 'type': 'Person', 'text': 'women'}], 'index': 'E3', 'realis': 'Actual', 'type': 'Attack'}\n",
      "{'nugget': {'startOffset': 324, 'index': 'T6', 'endOffset': 332, 'text': 'breached'}, 'subtype': 'Databreach', 'argument': [{'startOffset': 300, 'index': 'T7', 'endOffset': 319, 'role': {'type': 'Attacker'}, 'type': 'Person', 'text': 'the member of staff'}], 'index': 'E2', 'realis': 'Actual', 'type': 'Attack'}\n",
      "{'nugget': {'startOffset': 97, 'index': 'T1', 'endOffset': 105, 'text': 'accessed'}, 'subtype': 'Databreach', 'argument': [{'startOffset': 74, 'index': 'T4', 'endOffset': 96, 'role': {'type': 'Compromised-Data'}, 'type': 'PII', 'text': 'their personal details'}, {'startOffset': 109, 'index': 'T2', 'endOffset': 126, 'role': {'type': 'Attacker'}, 'type': 'Person', 'text': 'a member of staff'}, {'startOffset': 130, 'index': 'T3', 'endOffset': 149, 'role': {'type': 'Victim'}, 'external_reference': {'dbpediaURI': 'http://dbpedia.org/resource/University_Hospital_Crosshouse', 'wikidataid': 'Q7894766'}, 'type': 'Organization', 'text': 'Crosshouse Hospital'}, {'startOffset': 56, 'index': 'T5', 'endOffset': 64, 'role': {'type': 'Victim'}, 'external_reference': {'wikidataid': 'Q181600'}, 'type': 'Person', 'text': 'patients'}], 'index': 'E1', 'realis': 'Actual', 'type': 'Attack'}\n",
      "{'nugget': {'startOffset': 407, 'index': 'T13', 'endOffset': 417, 'text': 'The breach'}, 'subtype': 'Databreach', 'argument': [{'startOffset': 435, 'index': 'T16', 'endOffset': 446, 'role': {'type': 'Compromised-Data'}, 'type': 'Data', 'text': 'information'}, {'startOffset': 455, 'index': 'T14', 'endOffset': 487, 'role': {'type': 'Victim'}, 'type': 'System', 'text': 'the Radiology Information System'}, {'startOffset': 492, 'index': 'T15', 'endOffset': 500, 'role': {'type': 'Victim'}, 'external_reference': {'wikidataid': 'Q181600'}, 'type': 'Person', 'text': 'patients'}], 'index': 'E4', 'realis': 'Actual', 'type': 'Attack'}\n",
      "{'nugget': {'startOffset': 615, 'index': 'T17', 'endOffset': 625, 'text': 'the breach'}, 'subtype': 'Databreach', 'argument': [{'startOffset': 643, 'index': 'T18', 'endOffset': 683, 'role': {'type': 'Time'}, 'type': 'Time', 'text': 'between April and September of this year'}, {'startOffset': 557, 'index': 'T23', 'endOffset': 574, 'role': {'type': 'Attacker'}, 'type': 'Person', 'text': 'A member of staff'}], 'index': 'E5', 'realis': 'Actual', 'type': 'Attack'}\n",
      "{'nugget': {'startOffset': 835, 'index': 'T21', 'endOffset': 844, 'text': 'accessing'}, 'subtype': 'Databreach', 'argument': [{'startOffset': 801, 'index': 'T20', 'endOffset': 818, 'role': {'type': 'Attacker'}, 'type': 'Person', 'text': 'a member of staff'}, {'startOffset': 845, 'index': 'T22', 'endOffset': 860, 'role': {'type': 'Compromised-Data'}, 'type': 'PII', 'text': 'patient records'}], 'index': 'E6', 'realis': 'Actual', 'type': 'Attack'}\n"
     ]
    }
   ],
   "source": [
    "for event in hopper[\"events\"]:\n",
    "    trigger = event['nugget']\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_seg_id = -1\n",
    "for i, sent_offsets in enumerate(seg_offsets):\n",
    "    \n",
    "    if sent_offsets[0][0] <= trigger['startOffset'] and trigger['endOffset'] <= sent_offsets[-1][1]:\n",
    "        tri_seg_id = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_start_id = -1\n",
    "tri_end_id = -1\n",
    "for i, token_offsets in enumerate(seg_offsets[tri_seg_id]):\n",
    "    '''\n",
    "    i表示第i个词在列表中的位置\n",
    "\n",
    "    '''\n",
    "    if token_offsets[0] == trigger[\"startOffset\"]:\n",
    "        tri_start_id = i\n",
    "        # print(tri_start_id)\n",
    "        ## 从第i个元素开始到最后，寻找end\n",
    "        for j in range(i, len(seg_offsets[tri_seg_id])):\n",
    "            if seg_offsets[tri_seg_id][j][1] == trigger[\"endOffset\"]:\n",
    "                tri_end_id = j + 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startOffset': 801, 'index': 'T20', 'endOffset': 818, 'role': {'type': 'Attacker'}, 'type': 'Person', 'text': 'a member of staff'}\n",
      "{'startOffset': 845, 'index': 'T22', 'endOffset': 860, 'role': {'type': 'Compromised-Data'}, 'type': 'PII', 'text': 'patient records'}\n"
     ]
    }
   ],
   "source": [
    "arguments = []\n",
    "if 'argument' in event:\n",
    "    for arg in event['argument']:\n",
    "        print(arg)\n",
    "        arg_seg_id = -1\n",
    "        for i, sent_offsets in enumerate(seg_offsets):\n",
    "            if sent_offsets[0][0] <= arg['startOffset'] and arg['endOffset'] <= sent_offsets[-1][1]:\n",
    "                arg_seg_id = i\n",
    "                break\n",
    "        if arg_seg_id == -1 or tri_seg_id != arg_seg_id:\n",
    "                            n_drop_arg += 1\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10001_Seg0_Ent0'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{obj['sourcefile'][:-4]}_Seg{tri_seg_id}_Ent{len(entity_mentions[tri_seg_id])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(objs, token_map, seg_map):\n",
    "    '''\n",
    "    objs:存储json文档的list\n",
    "    token_map:分句子\n",
    "    '''\n",
    "    data = []\n",
    "    n_drop_event = 0\n",
    "    n_drop_arg = 0\n",
    "    for obj in tqdm(objs, ncols=100):\n",
    "        \n",
    "        text_tokens = [[obj[\"content\"][si:ei] for si, ei in sent] for sent in token_map[obj[\"sourcefile\"]]]\n",
    "        n_sent = len(text_tokens) # 多少句\n",
    "        sent_lens = [len(s) for s in text_tokens] # 每句长度\n",
    "        \n",
    "        sents = seg_map[obj[\"sourcefile\"]]\n",
    "        n_seg = len(sents)\n",
    "        \n",
    "        entity_mentions = defaultdict(list)\n",
    "        event_mentions = defaultdict(list)\n",
    "        sent_offsets = token_map[obj[\"sourcefile\"]]\n",
    "        seg_offsets = []\n",
    "        for si, ei in sents:\n",
    "            segs = []\n",
    "            for i in range(si, ei):\n",
    "                segs.extend(sent_offsets[i])\n",
    "            seg_offsets.append(segs)\n",
    "                \n",
    "        for hopper in obj['cyberevent']['hopper']:## [0]?\n",
    "            for event in hopper[\"events\"]:\n",
    "                trigger = event['nugget']\n",
    "                tri_seg_id = -1\n",
    "                for i, sent_offsets in enumerate(seg_offsets):\n",
    "                    if sent_offsets[0][0] <= trigger['startOffset'] and trigger['endOffset'] <= sent_offsets[-1][1]:\n",
    "                        tri_seg_id = i\n",
    "                        break\n",
    "                if tri_seg_id == -1:\n",
    "                    n_drop_event += 1\n",
    "                    continue\n",
    "                    \n",
    "                tri_start_id = -1\n",
    "                tri_end_id = -1\n",
    "                for i, token_offsets in enumerate(seg_offsets[tri_seg_id]):\n",
    "                    if token_offsets[0] == trigger[\"startOffset\"]:\n",
    "                        tri_start_id = i\n",
    "                        for j in range(i, len(seg_offsets[tri_seg_id])):\n",
    "                            if seg_offsets[tri_seg_id][j][1] == trigger[\"endOffset\"]:\n",
    "                                tri_end_id = j + 1\n",
    "                        break\n",
    "                \n",
    "                if tri_start_id == -1 or tri_end_id == -1:\n",
    "                    if obj['content'][trigger[\"startOffset\"]:trigger[\"endOffset\"]] != trigger[\"text\"] and obj['content'][trigger[\"startOffset\"]-1:trigger[\"endOffset\"]-1] == trigger[\"text\"]:\n",
    "                        tri_start_id = -1\n",
    "                        tri_end_id = -1\n",
    "                        for i, token_offsets in enumerate(seg_offsets[tri_seg_id]):\n",
    "                            if token_offsets[0] == trigger[\"startOffset\"]-1:\n",
    "                                tri_start_id = i\n",
    "                                for j in range(i, len(seg_offsets[tri_seg_id])):\n",
    "                                    if seg_offsets[tri_seg_id][j][1] == trigger[\"endOffset\"]-1:\n",
    "                                        tri_end_id = j + 1\n",
    "                                break\n",
    "                        \n",
    "                        if tri_start_id == -1 or tri_end_id == -1:\n",
    "                            n_drop_event += 1\n",
    "                            continue\n",
    "                    else:\n",
    "                        n_drop_event += 1\n",
    "                        continue\n",
    "                    \n",
    "                arguments = []\n",
    "                if 'argument' in event:\n",
    "                    for arg in event['argument']:\n",
    "                        arg_seg_id = -1\n",
    "                        for i, sent_offsets in enumerate(seg_offsets):\n",
    "                            if sent_offsets[0][0] <= arg['startOffset'] and arg['endOffset'] <= sent_offsets[-1][1]:\n",
    "                                arg_seg_id = i\n",
    "                                break\n",
    "                        if arg_seg_id == -1 or tri_seg_id != arg_seg_id:\n",
    "                            n_drop_arg += 1\n",
    "                            continue\n",
    "                            \n",
    "                        start_id = -1\n",
    "                        end_id = -1\n",
    "                        for i, token_offsets in enumerate(seg_offsets[arg_seg_id]):\n",
    "                            if token_offsets[0] == arg[\"startOffset\"]:\n",
    "                                start_id = i\n",
    "                                for j in range(i, len(seg_offsets[arg_seg_id])):\n",
    "                                    if seg_offsets[arg_seg_id][j][1] == arg[\"endOffset\"]:\n",
    "                                        end_id = j + 1\n",
    "                                break\n",
    "\n",
    "                        if start_id == -1 or end_id == -1:\n",
    "                            if obj['content'][arg[\"startOffset\"]:arg[\"endOffset\"]] != arg[\"text\"] and obj['content'][arg[\"startOffset\"]-1:arg[\"endOffset\"]-1] == arg[\"text\"]:\n",
    "                                start_id = -1\n",
    "                                end_id = -1\n",
    "                                \n",
    "                                for i, token_offsets in enumerate(seg_offsets[arg_seg_id]):\n",
    "                                    if token_offsets[0] == arg[\"startOffset\"]-1:\n",
    "                                        start_id = i\n",
    "                                        for j in range(i, len(seg_offsets[arg_seg_id])):\n",
    "                                            if seg_offsets[arg_seg_id][j][1] == arg[\"endOffset\"]-1:\n",
    "                                                end_id = j + 1\n",
    "                                        break\n",
    "                                \n",
    "                                if start_id == -1 or end_id == -1:\n",
    "                                    n_drop_arg += 1\n",
    "                                    continue\n",
    "                            else:\n",
    "                                n_drop_arg += 1\n",
    "                                continue\n",
    "                        \n",
    "                        entity_id = f\"{obj['sourcefile'][:-4]}_Seg{tri_seg_id}_Ent{len(entity_mentions[tri_seg_id])}\"\n",
    "                        entity = {\n",
    "                            \"id\": entity_id, \n",
    "                            \"text\": arg[\"text\"], \n",
    "                            \"entity_type\": \"Entity\", \n",
    "                            \"start\": start_id, \n",
    "                            \"end\": end_id, \n",
    "                        }\n",
    "                        entity_mentions[tri_seg_id].append(entity)\n",
    "                        \n",
    "                        argument = {\n",
    "                            \"entity_id\": entity_id, \n",
    "                            \"role\": arg[\"role\"][\"type\"], \n",
    "                            \"text\": arg[\"text\"], \n",
    "                            \"start\": start_id, \n",
    "                            \"end\": end_id, \n",
    "                        }\n",
    "                        arguments.append(argument)\n",
    "                    arguments.sort(key=lambda x: (x[\"start\"], x[\"end\"]))\n",
    "                \n",
    "                event_ = {\n",
    "                    \"id\": f\"{obj['sourcefile'][:-4]}_Seg{tri_seg_id}_Evt{len(event_mentions[tri_seg_id])}\",\n",
    "                    \"event_type\": f\"{event['type']}:{event['subtype']}\",\n",
    "                    \"trigger\": {\n",
    "                        \"text\": trigger[\"text\"], \n",
    "                        \"start\": tri_start_id, \n",
    "                        \"end\": tri_end_id, \n",
    "                    },\n",
    "                    \"arguments\": arguments, \n",
    "                }\n",
    "                event_mentions[tri_seg_id].append(event_)\n",
    "                \n",
    "        for i in range(n_seg):\n",
    "            entity_mentions_ = entity_mentions[i]\n",
    "            event_mentions_ = event_mentions[i]\n",
    "            \n",
    "            entity_mentions_ = sorted(entity_mentions_, key=lambda x: (x[\"start\"], x[\"end\"]))\n",
    "            event_mentions_ = sorted(event_mentions_, key=lambda x: (x[\"trigger\"][\"start\"], x[\"trigger\"][\"end\"]))\n",
    "            tokens = [t for j in range(sents[i][0], sents[i][1]) for t in text_tokens[j]]\n",
    "            \n",
    "            dt = {\n",
    "                \"doc_id\": obj['sourcefile'][:-4], \n",
    "                \"wnd_id\": f\"{obj['sourcefile'][:-4]}_{i}\", \n",
    "                \"text\": obj[\"content\"][seg_offsets[i][0][0]:seg_offsets[i][-1][1]], \n",
    "                \"tokens\": tokens, \n",
    "                \"event_mentions\": event_mentions_, \n",
    "                \"entity_mentions\": entity_mentions_, \n",
    "                \"lang\": \"en\", \n",
    "            }\n",
    "            data.append(dt)\n",
    "        \n",
    "    print(f\"Number of dropped events: {n_drop_event}\")\n",
    "    print(f\"Number of dropped arguments: {n_drop_arg}\")\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 701/701 [00:00<00:00, 890.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped events: 4\n",
      "Number of dropped arguments: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = convert_format(train_objs, token_map, seg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': '10001',\n",
       " 'wnd_id': '10001_0',\n",
       " 'text': 'POLICE have launched an investigation after a number of patients have had their personal details accessed by a member of staff at Crosshouse Hospital. Those affected, believed to be mainly women, were notified that information, including their phone numbers and addresses, had been accessed and that the member of staff who breached their privacy had ‘no legitimate clinical or administrative requirement’. The breach came from within information held in the Radiology Information System and patients affected had all recently been referred for an X-ray.   A member of staff has been \\'excluded from work\\' following the breach which took place between April and September of this year.  Dr Alison Graham, Medical Director for the NHS Ayrshire & Arran said: \"NHS Ayrshire & Arran has been made aware of a member of staff inappropriately accessing patient records. This individual is currently excluded from work.\" We are currently investigating and are contacting a number of patients to ascertain the extent of this breach. We wish to apologise to anyone affected by this. We take patient confidentially extremely serious and will ensure a full investigation is conducted. \"We are working closely with Police Scotland and the Information Commissioner’s Office. As this is an ongoing police investigation, we are not able to confirm any further details.\"  </text>',\n",
       " 'tokens': ['POLICE',\n",
       "  'have',\n",
       "  'launched',\n",
       "  'an',\n",
       "  'investigation',\n",
       "  'after',\n",
       "  'a',\n",
       "  'number',\n",
       "  'of',\n",
       "  'patients',\n",
       "  'have',\n",
       "  'had',\n",
       "  'their',\n",
       "  'personal',\n",
       "  'details',\n",
       "  'accessed',\n",
       "  'by',\n",
       "  'a',\n",
       "  'member',\n",
       "  'of',\n",
       "  'staff',\n",
       "  'at',\n",
       "  'Crosshouse',\n",
       "  'Hospital',\n",
       "  '.',\n",
       "  'Those',\n",
       "  'affected',\n",
       "  ',',\n",
       "  'believed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'mainly',\n",
       "  'women',\n",
       "  ',',\n",
       "  'were',\n",
       "  'notified',\n",
       "  'that',\n",
       "  'information',\n",
       "  ',',\n",
       "  'including',\n",
       "  'their',\n",
       "  'phone',\n",
       "  'numbers',\n",
       "  'and',\n",
       "  'addresses',\n",
       "  ',',\n",
       "  'had',\n",
       "  'been',\n",
       "  'accessed',\n",
       "  'and',\n",
       "  'that',\n",
       "  'the',\n",
       "  'member',\n",
       "  'of',\n",
       "  'staff',\n",
       "  'who',\n",
       "  'breached',\n",
       "  'their',\n",
       "  'privacy',\n",
       "  'had',\n",
       "  '‘',\n",
       "  'no',\n",
       "  'legitimate',\n",
       "  'clinical',\n",
       "  'or',\n",
       "  'administrative',\n",
       "  'requirement',\n",
       "  '’',\n",
       "  '.',\n",
       "  'The',\n",
       "  'breach',\n",
       "  'came',\n",
       "  'from',\n",
       "  'within',\n",
       "  'information',\n",
       "  'held',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Radiology',\n",
       "  'Information',\n",
       "  'System',\n",
       "  'and',\n",
       "  'patients',\n",
       "  'affected',\n",
       "  'had',\n",
       "  'all',\n",
       "  'recently',\n",
       "  'been',\n",
       "  'referred',\n",
       "  'for',\n",
       "  'an',\n",
       "  'X',\n",
       "  '-ray',\n",
       "  '.',\n",
       "  'A',\n",
       "  'member',\n",
       "  'of',\n",
       "  'staff',\n",
       "  'has',\n",
       "  'been',\n",
       "  \"'\",\n",
       "  'excluded',\n",
       "  'from',\n",
       "  'work',\n",
       "  \"'\",\n",
       "  'following',\n",
       "  'the',\n",
       "  'breach',\n",
       "  'which',\n",
       "  'took',\n",
       "  'place',\n",
       "  'between',\n",
       "  'April',\n",
       "  'and',\n",
       "  'September',\n",
       "  'of',\n",
       "  'this',\n",
       "  'year',\n",
       "  '.',\n",
       "  'Dr',\n",
       "  'Alison',\n",
       "  'Graham',\n",
       "  ',',\n",
       "  'Medical',\n",
       "  'Director',\n",
       "  'for',\n",
       "  'the',\n",
       "  'NHS',\n",
       "  'Ayrshire',\n",
       "  '&',\n",
       "  'Arran',\n",
       "  'said',\n",
       "  ':',\n",
       "  '\"',\n",
       "  'NHS',\n",
       "  'Ayrshire',\n",
       "  '&',\n",
       "  'Arran',\n",
       "  'has',\n",
       "  'been',\n",
       "  'made',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'a',\n",
       "  'member',\n",
       "  'of',\n",
       "  'staff',\n",
       "  'inappropriately',\n",
       "  'accessing',\n",
       "  'patient',\n",
       "  'records',\n",
       "  '.',\n",
       "  'This',\n",
       "  'individual',\n",
       "  'is',\n",
       "  'currently',\n",
       "  'excluded',\n",
       "  'from',\n",
       "  'work',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'We',\n",
       "  'are',\n",
       "  'currently',\n",
       "  'investigating',\n",
       "  'and',\n",
       "  'are',\n",
       "  'contacting',\n",
       "  'a',\n",
       "  'number',\n",
       "  'of',\n",
       "  'patients',\n",
       "  'to',\n",
       "  'ascertain',\n",
       "  'the',\n",
       "  'extent',\n",
       "  'of',\n",
       "  'this',\n",
       "  'breach',\n",
       "  '.',\n",
       "  'We',\n",
       "  'wish',\n",
       "  'to',\n",
       "  'apologise',\n",
       "  'to',\n",
       "  'anyone',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'this',\n",
       "  '.',\n",
       "  'We',\n",
       "  'take',\n",
       "  'patient',\n",
       "  'confidentially',\n",
       "  'extremely',\n",
       "  'serious',\n",
       "  'and',\n",
       "  'will',\n",
       "  'ensure',\n",
       "  'a',\n",
       "  'full',\n",
       "  'investigation',\n",
       "  'is',\n",
       "  'conducted',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'We',\n",
       "  'are',\n",
       "  'working',\n",
       "  'closely',\n",
       "  'with',\n",
       "  'Police',\n",
       "  'Scotland',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Information',\n",
       "  'Commissioner',\n",
       "  '’s',\n",
       "  'Office',\n",
       "  '.',\n",
       "  'As',\n",
       "  'this',\n",
       "  'is',\n",
       "  'an',\n",
       "  'ongoing',\n",
       "  'police',\n",
       "  'investigation',\n",
       "  ',',\n",
       "  'we',\n",
       "  'are',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'confirm',\n",
       "  'any',\n",
       "  'further',\n",
       "  'details',\n",
       "  '.',\n",
       "  '\"',\n",
       "  '</',\n",
       "  'text',\n",
       "  '>'],\n",
       " 'event_mentions': [{'id': '10001_Seg0_Evt2',\n",
       "   'event_type': 'Attack:Databreach',\n",
       "   'trigger': {'text': 'accessed', 'start': 15, 'end': 16},\n",
       "   'arguments': [{'entity_id': '10001_Seg0_Ent8',\n",
       "     'role': 'Victim',\n",
       "     'text': 'patients',\n",
       "     'start': 9,\n",
       "     'end': 10},\n",
       "    {'entity_id': '10001_Seg0_Ent5',\n",
       "     'role': 'Compromised-Data',\n",
       "     'text': 'their personal details',\n",
       "     'start': 12,\n",
       "     'end': 15},\n",
       "    {'entity_id': '10001_Seg0_Ent6',\n",
       "     'role': 'Attacker',\n",
       "     'text': 'a member of staff',\n",
       "     'start': 17,\n",
       "     'end': 21},\n",
       "    {'entity_id': '10001_Seg0_Ent7',\n",
       "     'role': 'Victim',\n",
       "     'text': 'Crosshouse Hospital',\n",
       "     'start': 22,\n",
       "     'end': 24}]},\n",
       "  {'id': '10001_Seg0_Evt0',\n",
       "   'event_type': 'Attack:Databreach',\n",
       "   'trigger': {'text': 'had been accessed', 'start': 46, 'end': 49},\n",
       "   'arguments': [{'entity_id': '10001_Seg0_Ent3',\n",
       "     'role': 'Victim',\n",
       "     'text': 'women',\n",
       "     'start': 32,\n",
       "     'end': 33},\n",
       "    {'entity_id': '10001_Seg0_Ent2',\n",
       "     'role': 'Compromised-Data',\n",
       "     'text': 'information',\n",
       "     'start': 37,\n",
       "     'end': 38},\n",
       "    {'entity_id': '10001_Seg0_Ent1',\n",
       "     'role': 'Compromised-Data',\n",
       "     'text': 'their phone numbers',\n",
       "     'start': 40,\n",
       "     'end': 43},\n",
       "    {'entity_id': '10001_Seg0_Ent0',\n",
       "     'role': 'Compromised-Data',\n",
       "     'text': 'addresses',\n",
       "     'start': 44,\n",
       "     'end': 45}]},\n",
       "  {'id': '10001_Seg0_Evt1',\n",
       "   'event_type': 'Attack:Databreach',\n",
       "   'trigger': {'text': 'breached', 'start': 56, 'end': 57},\n",
       "   'arguments': [{'entity_id': '10001_Seg0_Ent4',\n",
       "     'role': 'Attacker',\n",
       "     'text': 'the member of staff',\n",
       "     'start': 51,\n",
       "     'end': 55}]},\n",
       "  {'id': '10001_Seg0_Evt3',\n",
       "   'event_type': 'Attack:Databreach',\n",
       "   'trigger': {'text': 'The breach', 'start': 69, 'end': 71},\n",
       "   'arguments': [{'entity_id': '10001_Seg0_Ent9',\n",
       "     'role': 'Compromised-Data',\n",
       "     'text': 'information',\n",
       "     'start': 74,\n",
       "     'end': 75},\n",
       "    {'entity_id': '10001_Seg0_Ent10',\n",
       "     'role': 'Victim',\n",
       "     'text': 'the Radiology Information System',\n",
       "     'start': 77,\n",
       "     'end': 81},\n",
       "    {'entity_id': '10001_Seg0_Ent11',\n",
       "     'role': 'Victim',\n",
       "     'text': 'patients',\n",
       "     'start': 82,\n",
       "     'end': 83}]},\n",
       "  {'id': '10001_Seg0_Evt4',\n",
       "   'event_type': 'Attack:Databreach',\n",
       "   'trigger': {'text': 'the breach', 'start': 106, 'end': 108},\n",
       "   'arguments': [{'entity_id': '10001_Seg0_Ent13',\n",
       "     'role': 'Attacker',\n",
       "     'text': 'A member of staff',\n",
       "     'start': 94,\n",
       "     'end': 98},\n",
       "    {'entity_id': '10001_Seg0_Ent12',\n",
       "     'role': 'Time',\n",
       "     'text': 'between April and September of this year',\n",
       "     'start': 111,\n",
       "     'end': 118}]},\n",
       "  {'id': '10001_Seg0_Evt5',\n",
       "   'event_type': 'Attack:Databreach',\n",
       "   'trigger': {'text': 'accessing', 'start': 148, 'end': 149},\n",
       "   'arguments': [{'entity_id': '10001_Seg0_Ent14',\n",
       "     'role': 'Attacker',\n",
       "     'text': 'a member of staff',\n",
       "     'start': 143,\n",
       "     'end': 147},\n",
       "    {'entity_id': '10001_Seg0_Ent15',\n",
       "     'role': 'Compromised-Data',\n",
       "     'text': 'patient records',\n",
       "     'start': 149,\n",
       "     'end': 151}]}],\n",
       " 'entity_mentions': [{'id': '10001_Seg0_Ent8',\n",
       "   'text': 'patients',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 9,\n",
       "   'end': 10},\n",
       "  {'id': '10001_Seg0_Ent5',\n",
       "   'text': 'their personal details',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 12,\n",
       "   'end': 15},\n",
       "  {'id': '10001_Seg0_Ent6',\n",
       "   'text': 'a member of staff',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 17,\n",
       "   'end': 21},\n",
       "  {'id': '10001_Seg0_Ent7',\n",
       "   'text': 'Crosshouse Hospital',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 22,\n",
       "   'end': 24},\n",
       "  {'id': '10001_Seg0_Ent3',\n",
       "   'text': 'women',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 32,\n",
       "   'end': 33},\n",
       "  {'id': '10001_Seg0_Ent2',\n",
       "   'text': 'information',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 37,\n",
       "   'end': 38},\n",
       "  {'id': '10001_Seg0_Ent1',\n",
       "   'text': 'their phone numbers',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 40,\n",
       "   'end': 43},\n",
       "  {'id': '10001_Seg0_Ent0',\n",
       "   'text': 'addresses',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 44,\n",
       "   'end': 45},\n",
       "  {'id': '10001_Seg0_Ent4',\n",
       "   'text': 'the member of staff',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 51,\n",
       "   'end': 55},\n",
       "  {'id': '10001_Seg0_Ent9',\n",
       "   'text': 'information',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 74,\n",
       "   'end': 75},\n",
       "  {'id': '10001_Seg0_Ent10',\n",
       "   'text': 'the Radiology Information System',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 77,\n",
       "   'end': 81},\n",
       "  {'id': '10001_Seg0_Ent11',\n",
       "   'text': 'patients',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 82,\n",
       "   'end': 83},\n",
       "  {'id': '10001_Seg0_Ent13',\n",
       "   'text': 'A member of staff',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 94,\n",
       "   'end': 98},\n",
       "  {'id': '10001_Seg0_Ent12',\n",
       "   'text': 'between April and September of this year',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 111,\n",
       "   'end': 118},\n",
       "  {'id': '10001_Seg0_Ent14',\n",
       "   'text': 'a member of staff',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 143,\n",
       "   'end': 147},\n",
       "  {'id': '10001_Seg0_Ent15',\n",
       "   'text': 'patient records',\n",
       "   'entity_type': 'Entity',\n",
       "   'start': 149,\n",
       "   'end': 151}],\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "# of Instances: 1047\n",
      "# of Docs: 701\n",
      "Max Length: 463\n",
      "# of Event Types: 5\n",
      "# of Events: 5980\n",
      "# of Role Types: 26\n",
      "# of Arguments: 15869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_statistics(data):\n",
    "    event_type_count = defaultdict(int)\n",
    "    role_type_count = defaultdict(int)\n",
    "    doc_ids = set()\n",
    "    max_len = 0\n",
    "    for dt in data:\n",
    "        max_len = max(max_len, len(dt[\"tokens\"]))\n",
    "        doc_ids.add(dt[\"doc_id\"])\n",
    "        for event in dt[\"event_mentions\"]:\n",
    "            event_type_count[event[\"event_type\"]] += 1\n",
    "            for argument in event[\"arguments\"]:\n",
    "                role_type_count[argument[\"role\"]] += 1\n",
    "    \n",
    "    print(f\"# of Instances: {len(data)}\")\n",
    "    print(f\"# of Docs: {len(doc_ids)}\")\n",
    "    print(f\"Max Length: {max_len}\")\n",
    "    print(f\"# of Event Types: {len(event_type_count)}\")\n",
    "    print(f\"# of Events: {sum(event_type_count.values())}\")\n",
    "    print(f\"# of Role Types: {len(role_type_count)}\")\n",
    "    print(f\"# of Arguments: {sum(role_type_count.values())}\")\n",
    "    # pprint(event_type_count)\n",
    "    print()\n",
    "print(\"Train\")\n",
    "get_statistics(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
